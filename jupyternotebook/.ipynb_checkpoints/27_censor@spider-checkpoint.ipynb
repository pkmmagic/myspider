{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timed out\n",
      "{'50428', '57875', '50365', '59483', '46990', '47094', '48633', '57882', '54993', '50362', '48673', '57755', '50618', '57562', '57914', '50610', '48726', '54976', '57910', '55023', '54971', '50608', '57744', '52690', '59346', '50458', '55003', '50555', '47095', '57886', '50551', '52635', '53840', '50644', '52642', '50476', '48697', '52623', '52583', '50420', '57859', '52684', '50328', '47114', '50617', '57381', '50636', '57605', '57634', '54771', '52613', '52725', '50310', '48716', '50323', '49979', '48671', '54748', '52691', '50345', '47100', '54998', '57805', '52625', '59501', '52593', '51598', '53848', '50386', '54770', '59498', '52624', '46959', '48668', '47098', '59478', '55019', '52647', '59484', '41984', '57772', '50348', '52615', '52634', '46986', '57879', '51815', '59470', '57870', '50378', '48721', '50632', '50471', '52723', '55012', '47109', '48630', '59477', '48667', '48712', '57893', '47097', '50637', '55016', '57737', '50329', '41981', '57900', '50343', '46999', '52652', '59502', '57792', '57710', '55015', '52611', '51591', '53858', '54759', '59487', '52728', '50641', '50606', '48702', '52578', '52695', '50423', '46948', '50552', '50631', '47111', '54942', '50474', '57897', '50390', '50619', '52575', '50550', '57799', '48710', '53857', '57921', '52698', '54772', '57902', '46940', '57639', '57829', '52640', '59476', '48676', '54763', '52621', '52639', '57923', '52643', '48690', '57672', '48682', '50396', '52686', '41995', '57912', '55009', '54767', '52661', '50438', '57810', '52662', '50393', '48645', '54750', '48635', '41977', '54777', '59492', '52644', '59472', '48869', '52609', '59491', '55001', '57869', '48670', '57926', '47096', '57885', '50340', '57819', '59480', '57674', '53708', '50611', '48619', '52633', '55007', '57698', '57748', '54937', '59352', '53969', '48674', '57888', '54994', '52603', '54982', '54991', '50317', '48681', '54978', '48706', '54974', '50620', '41973', '51707', '48620', '41967', '52720', '57766', '52618', '57901', '57654', '53834', '50455', '50525', '54979', '57877', '46977', '57622', '57917', '47101', '55061', '54775', '59349', '57775', '57780', '52648', '52607', '54997', '57677', '59497', '59474', '48640', '57668', '53706', '47113', '47102', '52653', '55010', '48636', '50482', '59499', '54939', '50324', '52599', '54773', '50452', '57903', '50556', '48625', '50351', '50369', '50616', '50625', '52587', '54754', '50464', '50307', '59479', '52596', '54760', '52619', '50627', '52724', '52651', '50434', '57873', '52590', '50461', '45132', '57905', '48618', '48695', '52641', '52649', '59503', '52726', '47002', '48665', '41987', '50392', '54972', '54987', '50375', '50443', '50448', '48622', '50398', '57883', '57927', '57866', '47106', '50549', '52702', '53963', '57908', '54747', '59495', '57661', '57558', '54990', '48678', '57916', '50333', '57786', '48629', '51643', '57868', '48699', '52660', '50603', '52636', '48626', '52650', '52622', '48686', '46995', '52605', '41990', '50529', '50634', '52616', '57918', '52638', '48624', '53709', '57675', '52646', '50417', '57907', '57617', '54038', '47099', '50352', '48680', '52688', '48683', '52645', '52663', '57919', '52631', '48617', '57644', '59489', '50315', '46972', '50326', '59471', '54755', '50501'}\n",
      "name 'diff' is not defined\n",
      "108.1579999923706\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0',\n",
    "'Cookie':'a22e7_c_stamp=1533181577; a22e7_readlog=%2C522626%2C98009%2C522542%2C; a22e7_ol_offset=133472; visid_incap_1639104=Jb5ILxvzTxmJ4cESKs8iTqZ6YlsAAAAAQUIPAAAAAAAAjBuqYIiX7PR9wNyLyeP9; incap_ses_635_1639104=Q5ROMjIz7w3RPRy42vnPCHCOa1sAAAAAstWE22TqFd7nblxlvdRA4g==; a22e7_lastpos=F27; __tins__19410549=%7B%22sid%22%3A%201533775480153%2C%20%22vd%22%3A%201%2C%20%22expires%22%3A%201533777280153%7D; __51cke__=; __51laig__=1; a22e7_lastvisit=660%091533775559%09%2F2048%2Fthread.php%3Ffid-27.html; a22e7_threadlog=%2C7%2C21%2C27%2C'\n",
    "}\n",
    "import requests, urllib.request, myspider, time \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "since = time.time()\n",
    "LibPath, NewPath = 'test2.txt', 'test3.txt'\n",
    "subpage_url_num_set = set()\n",
    "All_set = set()\n",
    "\n",
    "def subpage(index,s):\n",
    "    for i in range(index,index+10):\n",
    "        try:\n",
    "            url = 'http://www.weiai2048.com/2048/thread.php?fid-27-page-'+str(i)+'.html'\n",
    "            result = urlopen(urllib.request.Request(url,headers=headers), timeout=30)\n",
    "            soup = BeautifulSoup(result,'html.parser')\n",
    "            myspider.get_num_set(soup,s)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def get_lib_write_new(LibPath,NewPath,s,subpage_url_num_set):\n",
    "    myspider.open2add(LibPath,s)\n",
    "    diff = subpage_url_num_set.difference(s)\n",
    "    myspider.open2w(NewPath,list(diff))\n",
    "    s.update(diff)\n",
    "    myspider.open2w(LibPath,sorted(list(s)))\n",
    "    return len(diff)\n",
    "\n",
    "try:\n",
    "    subpage(110,subpage_url_num_set)\n",
    "    print(subpage_url_num_set)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    length = get_lib_write_new(LibPath,NewPath,All_set,subpage_url_num_set)\n",
    "    print(str(len(subpage_url_num_set))+' get and '+ str(length)+ ' new numbers')\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "print (time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new num list successfully get from test3.txt\n",
      "360 left\n",
      "359 left\n",
      "358 left\n",
      "357 left\n"
     ]
    }
   ],
   "source": [
    "#Part B: get all the url\n",
    "\n",
    "headers = {\n",
    "'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.221 Safari/537.36 SE 2.X MetaSr 1.0',\n",
    "'Cookie':'a22e7_c_stamp=1533181577; a22e7_readlog=%2C522626%2C98009%2C522542%2C; a22e7_ol_offset=133472; visid_incap_1639104=Jb5ILxvzTxmJ4cESKs8iTqZ6YlsAAAAAQUIPAAAAAAAAjBuqYIiX7PR9wNyLyeP9; incap_ses_635_1639104=Q5ROMjIz7w3RPRy42vnPCHCOa1sAAAAAstWE22TqFd7nblxlvdRA4g==; a22e7_lastpos=F27; __tins__19410549=%7B%22sid%22%3A%201533775480153%2C%20%22vd%22%3A%201%2C%20%22expires%22%3A%201533777280153%7D; __51cke__=; __51laig__=1; a22e7_lastvisit=660%091533775559%09%2F2048%2Fthread.php%3Ffid-27.html; a22e7_threadlog=%2C7%2C21%2C27%2C'\n",
    "}\n",
    "import requests, urllib.request, myspider, time, os \n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "UrlPath, NewPath, logPath = 'test1.txt', 'test3.txt', 'timelog.csv'\n",
    "\n",
    "def get_num_list(NewPath):\n",
    "    num_list = []\n",
    "    num_set = set()\n",
    "    myspider.open2add(NewPath,num_set)\n",
    "    num_list = list(num_set)\n",
    "    return num_list\n",
    "\n",
    "def get_url(num,l):\n",
    "    req = urllib.request.Request('http://www.weiai2048.com/2048/read.php?tid-' + num + '.html',headers=headers)\n",
    "    result = urlopen(req, timeout=45)\n",
    "    soup2 = BeautifulSoup(result,'html.parser')\n",
    "    myspider.get_list(soup2,l)\n",
    "\n",
    "def get_from_num(num_list):\n",
    "    master_list = []\n",
    "    for num in num_list:\n",
    "        try:\n",
    "            image_url_list = []\n",
    "            image_url_list.append(num)\n",
    "            get_url(num,image_url_list)\n",
    "            master_list.append(image_url_list)\n",
    "            print(str(len(num_list)-num_list.index(num))+' left')\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return master_list\n",
    "\n",
    "def write_master_list(UrlPath,master_list):\n",
    "    myspider.open2w(UrlPath,master_list)\n",
    "    \n",
    "def get_url_log(logPath,num_list,time_elapsed):\n",
    "    time_list = []\n",
    "    myspider.readlog(logPath,time_list)\n",
    "    time_list.append([str(time.time()),str(len(num_list)),str(time_elapsed)])\n",
    "    myspider.login(logPath,time_list)\n",
    "    \n",
    "def go_url(NewPath,UrlPath,logPath):\n",
    "    since=time.time()\n",
    "    try:\n",
    "        num_list = get_num_list(NewPath)\n",
    "        print('new num list successfully get from %s'% NewPath)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        master_list = get_from_num(num_list)\n",
    "        print('master list successfully get from num_list')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    time_elapsed = round((time.time() - since ),2)       \n",
    "    print(str(len(master_list)) + ' master get. It takes %s seconds.' % str(time_elapsed))\n",
    "    try:\n",
    "        write_master_list(UrlPath,master_list)\n",
    "        print('master list successfully written')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        get_url_log(logPath,num_list,time_elapsed)\n",
    "        print('get url successfully logged in %s' %logPath)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "go_url(NewPath,UrlPath,logPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "master list append success\n",
      "214,100\n",
      "213,101\n",
      "212,102\n",
      "211,103\n",
      "210,104\n",
      "209,105\n",
      "208,106\n",
      "207,107\n",
      "206,108\n",
      "205,109\n",
      "204,110\n",
      "203,111\n",
      "202,112\n",
      "201,113\n",
      "200,114\n",
      "199,115\n",
      "198,116\n",
      "197,117\n",
      "196,118\n",
      "195,119\n",
      "194,120\n",
      "193,121\n",
      "192,122\n",
      "191,123\n",
      "190,124\n",
      "189,125\n",
      "188,126\n",
      "187,127\n",
      "186,128\n",
      "185,129\n",
      "184,130\n",
      "183,131\n",
      "182,132\n",
      "181,133\n",
      "180,134\n",
      "179,135\n",
      "178,136\n",
      "177,137\n",
      "176,138\n",
      "175,139\n",
      "174,140\n",
      "173,141\n",
      "172,142\n",
      "171,143\n",
      "170,144\n",
      "169,145\n",
      "168,146\n",
      "166,148\n",
      "165,149\n",
      "164,150\n",
      "163,151\n",
      "162,152\n",
      "161,153\n",
      "160,154\n",
      "159,155\n",
      "158,156\n",
      "157,157\n",
      "156,158\n",
      "155,159\n",
      "154,160\n",
      "153,161\n",
      "152,162\n",
      "151,163\n",
      "150,164\n",
      "149,165\n",
      "148,166\n",
      "147,167\n",
      "146,168\n",
      "145,169\n",
      "144,170\n",
      "143,171\n",
      "142,172\n",
      "141,173\n",
      "140,174\n",
      "139,175\n",
      "138,176\n",
      "137,177\n",
      "136,178\n",
      "download 68413 failed: HTTPConnectionPool(host='s3.3wkk.org', port=80): Max retries exceeded with url: /img/2018_5aec11b9ded15.jpg (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000000005F267F0>: Failed to establish a new connection: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。',))\n",
      "134,180\n",
      "133,181\n",
      "132,182\n",
      "131,183\n",
      "130,184\n",
      "129,185\n",
      "128,186\n",
      "127,187\n",
      "126,188\n",
      "125,189\n",
      "124,190\n",
      "123,191\n",
      "122,192\n",
      "121,193\n",
      "120,194\n",
      "119,195\n",
      "118,196\n",
      "117,197\n",
      "116,198\n",
      "115,199\n",
      "114,200\n",
      "113,201\n",
      "112,202\n",
      "111,203\n",
      "110,204\n",
      "109,205\n",
      "108,206\n",
      "107,207\n",
      "106,208\n",
      "105,209\n",
      "104,210\n",
      "103,211\n",
      "102,212\n",
      "101,213\n",
      "100,214\n",
      "99,215\n",
      "98,216\n",
      "97,217\n",
      "96,218\n",
      "95,219\n",
      "94,220\n",
      "93,221\n",
      "download 59572 failed: HTTPConnectionPool(host='www.lmgun.com', port=80): Max retries exceeded with url: /99889988989655665565656565kkjjkdx.jpg (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000000005F47CC0>: Failed to establish a new connection: [Errno 11004] getaddrinfo failed',))\n",
      "91,223\n",
      "90,224\n",
      "89,225\n",
      "88,226\n",
      "87,227\n",
      "86,228\n",
      "85,229\n",
      "84,230\n",
      "83,231\n",
      "82,232\n",
      "81,233\n",
      "80,234\n",
      "79,235\n",
      "78,236\n",
      "77,237\n",
      "76,238\n",
      "75,239\n",
      "74,240\n",
      "73,241\n",
      "72,242\n",
      "71,243\n",
      "70,244\n",
      "69,245\n",
      "68,246\n",
      "67,247\n",
      "66,248\n",
      "65,249\n",
      "64,250\n",
      "63,251\n",
      "62,252\n",
      "61,253\n",
      "60,254\n",
      "59,255\n",
      "58,256\n",
      "57,257\n",
      "56,258\n",
      "55,259\n",
      "54,260\n",
      "53,261\n",
      "52,262\n",
      "51,263\n",
      "50,264\n",
      "49,265\n",
      "48,266\n",
      "47,267\n",
      "46,268\n",
      "45,269\n",
      "44,270\n",
      "43,271\n",
      "42,272\n",
      "41,273\n",
      "40,274\n",
      "39,275\n",
      "38,276\n",
      "37,277\n",
      "36,278\n",
      "35,279\n",
      "34,280\n",
      "33,281\n",
      "32,282\n",
      "31,283\n",
      "30,284\n",
      "29,285\n",
      "28,286\n",
      "27,287\n",
      "26,288\n",
      "25,289\n",
      "24,290\n",
      "23,291\n",
      "22,292\n",
      "21,293\n",
      "20,294\n",
      "19,295\n",
      "18,296\n",
      "17,297\n",
      "16,298\n",
      "15,299\n",
      "14,300\n",
      "13,301\n",
      "12,302\n",
      "11,303\n",
      "10,304\n",
      "9,305\n",
      "8,306\n",
      "7,307\n",
      "6,308\n",
      "5,309\n",
      "4,310\n",
      "3,311\n",
      "2,312\n",
      "1,313\n",
      "download success\n",
      "238.22\n",
      "logging success\n"
     ]
    }
   ],
   "source": [
    "#directly download the first jpg for censor\n",
    "import myspider,requests\n",
    "masterPath, filePath,logPath = r'test1.txt', r'd:\\censor', r'downloadtimelog.csv'\n",
    "\n",
    "def appendmaster(path):\n",
    "    master_list=[]\n",
    "    myspider.open2append(path,master_list)\n",
    "    return master_list\n",
    "\n",
    "def download(start_index,master_list):\n",
    "    n=0\n",
    "    for i in range(start_index,len(master_list)):\n",
    "        if len(master_list[i].split(','))>1:\n",
    "            try:\n",
    "                res=requests.get(master_list[i].split(',')[1],timeout=30)\n",
    "                with open(filePath + '\\\\%s.jpg'% master_list[i].split(',')[0],'wb') as f:\n",
    "                    f.write(res.content) \n",
    "                n+=1\n",
    "                print(str(len(master_list)-i)+','+str(i))\n",
    "            except Exception as e:\n",
    "                print('download ' + master_list[i].split(',')[0]+ ' failed: ' + str(e))\n",
    "    return n\n",
    "\n",
    "def logtime(logPath,log):\n",
    "    time_list = []\n",
    "    myspider.readlog(logPath,time_list)\n",
    "    time_list.append(log)\n",
    "    myspider.login(logPath,time_list)\n",
    "\n",
    "\n",
    "def go_download(masterPath,logPath,start_index):\n",
    "    import time\n",
    "    since=time.time()\n",
    "    try:\n",
    "        master_list = appendmaster(masterPath)\n",
    "        print('master list append success from %s'%masterPath)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    try:\n",
    "        n = download(start_index,master_list)\n",
    "        print('%s jpgs download success from master list'% str(n))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    time_elapsed = round((time.time() - since ),2)  \n",
    "    print(time_elapsed)\n",
    "    try:\n",
    "        logtime(logPath,[str(time.time()),str(len(master_list)),str(time_elapsed)])\n",
    "        print('logging to %s success'% logPath)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "go_download(masterPath,logPath,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "censored num list get\n",
      "['59529', '59535', '59549', '59550', '59556', '59560', '60315', '60333', '60626', '60638', '60653.jpg.baiduyun', '60653.jpg.baiduyun.downloading', '61034', '61081', '61089', '61097', '61099', '61100', '61102', '61109', '61117', '61119', '61121', '61135', '61137', '61146', '61170', '61173', '61194', '61195', '61199', '61205', '61210', '61265', '61287', '61306', '61842', '61847', '61853', '61946', '61980', '61981', '62737', '62741', '62746', '62761', '62763', '62765', '62774', '62789', '62803', '62833', '62840', '62841', '62846', '62847', '62852', '62855', '62863', '62871', '63898.jpg.baiduyun', '63898.jpg.baiduyun.downloading', '63918.jpg.baiduyun', '63918.jpg.baiduyun.downloading', '64273', '64287', '64290', '64294', '64808', '64810', '64815', '64816', '64825', '64826', '64827', '64831', '64833', '64835', '64836', '64837', '64838', '64839', '64849', '64853', '64854', '64859', '64865', '64866', '64869', '64875', '64876', '64880', '68418', '68423', '68428', '68429', '68432', '68433', '68437', '68438', '68440', '68455', '68461', '68465', '68468', '68484']\n",
      "all num list get\n",
      "crossing success: 100 get\n"
     ]
    }
   ],
   "source": [
    "#read censored jpg and cross it with the new load\n",
    "#take the remaining as index to locate all the urls in master then save them in 6.txt for popping\n",
    "import myspider, os\n",
    "censorPath,UrlPath = r'f:\\BaiduNetdiskDownload\\censor','test1.txt'\n",
    "finalPath = 'text6.txt'\n",
    "\n",
    "def censored(censorPath):\n",
    "    l = []\n",
    "    for i in os.listdir(censorPath):\n",
    "        s = censorPath +'\\\\'+ i\n",
    "        l.append(s.split('\\\\').pop().split('/').pop().rsplit('.', 1)[0])\n",
    "    return l\n",
    "\n",
    "def appendall(UrlPath):\n",
    "    l = []\n",
    "    myspider.open2append(UrlPath,l)\n",
    "    return l\n",
    "\n",
    "def cross(l1,l2):\n",
    "    n=0\n",
    "    for i in l1:\n",
    "        for j in range(len(l2)):\n",
    "            if l2[j][0:6].strip(',')==i:\n",
    "                n+=1\n",
    "                final_list = l2[j].split(',')[1:]\n",
    "                myspider.open2a(finalPath,final_list)\n",
    "    return n\n",
    "\n",
    "try:\n",
    "    censored_num_list = censored(censorPath)\n",
    "    print('censored num list get')\n",
    "    print(censored_num_list)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    all_list = appendall(UrlPath)\n",
    "    print('all num list get')\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    n = cross(censored_num_list,all_list)\n",
    "    print('crossing success: %s get' % str(n))\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'64288'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_list[1][0:6].strip(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in censored_num_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(l)):\n",
    "    print(l[j][0:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list = l[j].split(',')[1:]\n",
    "print(final_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
